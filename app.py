import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import speech_to_text

# --- 1. Cáº¤U HÃŒNH TRANG ---
st.set_page_config(
    page_title='TRá»¢ LÃ Há»ŒC Táº¬P & GIáº¢NG Dáº Y NGá»® VÄ‚N - "VÄ‚N SÄ¨ Sá»"',
    page_icon="ğŸ“š",
    layout="centered"
)

# --- 2. Cáº¤U HÃŒNH API KEY ---
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("ChÆ°a tÃ¬m tháº¥y API Key. Vui lÃ²ng kiá»ƒm tra láº¡i Secrets.")

# --- 3. Ná»˜I DUNG NHáº¬P VAI (SYSTEM INSTRUCTION) ---
sys_prompt = """
SYSTEM INSTRUCTIONS: TRá»¢ LÃ Há»ŒC Táº¬P & GIáº¢NG Dáº Y NGá»® VÄ‚N - "VÄ‚N SÄ¨ Sá»"
I. Äá»ŠNH DANH: Trá»£ lÃ½ chuyÃªn mÃ´n cho GiÃ¡o viÃªn & Mentor cho Há»c sinh trÆ°á»ng PTDTBT THCS Há»‘ QuÃ¡ng PhÃ¬n.
II. GIAO THá»¨C:
1. GIÃO VIÃŠN: ChuyÃªn nghiá»‡p, dÃ¹ng ngá»¯ liá»‡u ngoÃ i SGK khi ra Ä‘á» (MÃ£ A Lá»nh, HÃ¹ng ÄÃ¬nh QuÃ½).
2. Há»ŒC SINH: ThÃ¢n thiá»‡n, khÃ´ng lÃ m bÃ i há»™, chá»‰ gá»£i Ã½.
III. KHO Dá»® LIá»†U: Æ¯u tiÃªn vÄƒn hÃ³a TuyÃªn Quang - HÃ  Giang.
"""

# --- 4. KHá»I Táº O MÃ” HÃŒNH (CÆ  CHáº¾ AN TOÃ€N CAO NHáº¤T) ---
generation_config = {"temperature": 1, "max_output_tokens": 8192}

# Thá»­ khá»Ÿi táº¡o mÃ´ hÃ¬nh tá»‘t nháº¥t (1.5 Flash)
try:
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash", 
        generation_config=generation_config,
        system_instruction=sys_prompt
    )
    # Náº¿u thÃ nh cÃ´ng, in log nhá» Ä‘á»ƒ biáº¿t (chá»‰ hiá»‡n khi cháº¡y local)
    print("Äang cháº¡y: Gemini 1.5 Flash")

except Exception as e:
    # Náº¿u lá»—i (do thÆ° viá»‡n cÅ© hoáº·c quota), chuyá»ƒn sang cháº¿ Ä‘á»™ "Sinh tá»“n" (Gemini Pro)
    # LÆ°u Ã½: Gemini Pro cÅ© khÃ´ng há»— trá»£ tham sá»‘ 'system_instruction' trong hÃ m khá»Ÿi táº¡o
    # nÃªn ta pháº£i bá» nÃ³ Ä‘i vÃ  "tiÃªm" nÃ³ vÃ o lá»‹ch sá»­ chat sau.
    model = genai.GenerativeModel(
        model_name="gemini-pro", 
        generation_config=generation_config
    )
    # ÄÃ¡nh dáº¥u lÃ  Ä‘ang dÃ¹ng báº£n cÅ© Ä‘á»ƒ xá»­ lÃ½ logic chÃ¨n prompt
    st.session_state.use_legacy_prompting = True
    print(f"Äang cháº¡y: Gemini Pro (Backup mode). Lá»—i trÆ°á»›c Ä‘Ã³: {e}")

# --- 5. GIAO DIá»†N CHAT ---
st.title("ğŸ“š VÄ‚N SÄ¨ Sá» - TRá»¢ LÃ NGá»® VÄ‚N")
st.caption("Trá»£ lÃ½ SÆ° pháº¡m Ngá»¯ VÄƒn - TrÆ°á»ng PTDTBT THCS Há»‘ QuÃ¡ng PhÃ¬n")

if "messages" not in st.session_state:
    st.session_state.messages = []
    # Náº¿u pháº£i dÃ¹ng cháº¿ Ä‘á»™ cÅ©, ta chÃ¨n cÃ¢u nháº­p vai vÃ o dÃ²ng Ä‘áº§u tiÃªn cá»§a lá»‹ch sá»­
    if "use_legacy_prompting" in st.session_state:
        st.session_state.messages.append({"role": "user", "content": sys_prompt})
        st.session_state.messages.append({"role": "model", "content": "TÃ´i Ä‘Ã£ hiá»ƒu nhiá»‡m vá»¥. TÃ´i lÃ  VÄƒn SÄ© Sá»‘."})

# Hiá»ƒn thá»‹ lá»‹ch sá»­ (Bá» qua cÃ¢u lá»‡nh há»‡ thá»‘ng náº¿u Ä‘ang dÃ¹ng cháº¿ Ä‘á»™ cÅ© Ä‘á»ƒ giao diá»‡n Ä‘áº¹p)
for i, message in enumerate(st.session_state.messages):
    # Náº¿u Ä‘ang dÃ¹ng cháº¿ Ä‘á»™ cÅ©, áº©n 2 dÃ²ng Ä‘áº§u (lÃ  dÃ²ng nháº­p vai) Ä‘i
    if "use_legacy_prompting" in st.session_state and i < 2:
        continue
    
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- 6. NHáº¬P LIá»†U & Xá»¬ LÃ ---
st.divider()
col_mic, col_info = st.columns([1, 4])
with col_mic:
    voice_text = speech_to_text(language='vi', start_prompt="ğŸ™ï¸ NÃ³i", stop_prompt="â¹ï¸ Gá»­i", just_once=True, key='STT')

prompt = voice_text if voice_text else st.chat_input("Em cáº§n tháº§y giÃºp gÃ¬ hÃ´m nay?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        # Chuáº©n bá»‹ lá»‹ch sá»­ chat Ä‘á»ƒ gá»­i
        history_for_model = [
            {"role": m["role"], "parts": [m["content"]]} 
            for m in st.session_state.messages 
            if m["role"] in ["user", "model"]
        ]
        
        chat_session = model.start_chat(history=history_for_model[:-1])
        
        with st.chat_message("assistant"):
            with st.spinner("Äang suy nghÄ©..."):
                response = chat_session.send_message(prompt)
                st.markdown(response.text)
        
        st.session_state.messages.append({"role": "model", "content": response.text})
        st.rerun() # LÃ m má»›i Ä‘á»ƒ xÃ³a text voice
        
    except Exception as e:
        st.error(f"Lá»—i káº¿t ná»‘i: {e}. Tháº§y hÃ£y thá»­ 'Reboot App' hoáº·c chá» 1 phÃºt.")
