import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import speech_to_text
import time

# --- 1. Cáº¤U HÃŒNH TRANG (ÄÃ£ sá»­a lá»—i dáº¥u ngoáº·c kÃ©p) ---
st.set_page_config(
    page_title='TRá»¢ LÃ Há»ŒC Táº¬P & GIáº¢NG Dáº Y NGá»® VÄ‚N - "VÄ‚N SÄ¨ Sá»"',
    page_icon="ğŸ“š",
    layout="centered"
)

# --- 2. Cáº¤U HÃŒNH API KEY ---
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.error("ChÆ°a tÃ¬m tháº¥y API Key. Vui lÃ²ng kiá»ƒm tra láº¡i Secrets.")

# --- 3. CHá»ˆ DáºªN Há»† THá»NG (Giá»¯ nguyÃªn ná»™i dung cá»§a tháº§y) ---
full_system_instruction = """
SYSTEM INSTRUCTIONS: TRá»¢ LÃ Há»ŒC Táº¬P & GIáº¢NG Dáº Y NGá»® VÄ‚N - "VÄ‚N SÄ¨ Sá»"
I. Äá»ŠNH DANH: Trá»£ lÃ½ chuyÃªn mÃ´n cho GiÃ¡o viÃªn & Mentor cho Há»c sinh trÆ°á»ng PTDTBT THCS Há»‘ QuÃ¡ng PhÃ¬n.
II. GIAO THá»¨C:
1. GIÃO VIÃŠN: ChuyÃªn nghiá»‡p, dÃ¹ng ngá»¯ liá»‡u ngoÃ i SGK khi ra Ä‘á» (MÃ£ A Lá»nh, HÃ¹ng ÄÃ¬nh QuÃ½).
2. Há»ŒC SINH: ThÃ¢n thiá»‡n, khÃ´ng lÃ m bÃ i há»™, chá»‰ gá»£i Ã½.
III. KHO Dá»® LIá»†U: Æ¯u tiÃªn vÄƒn hÃ³a TuyÃªn Quang - HÃ  Giang.
"""

# --- 4. KHá»I Táº O MÃ” HÃŒNH (CÆ  CHáº¾ AN TOÃ€N 2 Lá»šP) ---
generation_config = {"temperature": 1, "max_output_tokens": 8192}

# Biáº¿n kiá»ƒm tra xem cÃ³ pháº£i dÃ¹ng cháº¿ Ä‘á»™ cÅ© khÃ´ng
if "is_legacy_mode" not in st.session_state:
    st.session_state.is_legacy_mode = False

try:
    # Æ¯u tiÃªn 1: Thá»­ cháº¡y Gemini 1.5 Flash (Báº£n má»›i, nhanh, ráº»)
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash", 
        generation_config=generation_config,
        system_instruction=full_system_instruction
    )
    # Kiá»ƒm tra thá»­ káº¿t ná»‘i ngay láº­p tá»©c
    model.count_tokens("test")
    st.session_state.is_legacy_mode = False

except Exception:
    # Æ¯u tiÃªn 2: Náº¿u lá»—i (do thÆ° viá»‡n cÅ© hoáº·c lá»—i Quota), tá»± Ä‘á»™ng lÃ¹i vá» Gemini Pro
    model = genai.GenerativeModel(
        model_name="gemini-pro", 
        generation_config=generation_config
    )
    st.session_state.is_legacy_mode = True # ÄÃ¡nh dáº¥u Ä‘ang dÃ¹ng báº£n cÅ©

# --- 5. GIAO DIá»†N CHAT ---
st.title("ğŸ“š VÄ‚N SÄ¨ Sá» - TRá»¢ LÃ NGá»® VÄ‚N")
if st.session_state.is_legacy_mode:
    st.caption("Äang cháº¡y cháº¿ Ä‘á»™ tÆ°Æ¡ng thÃ­ch (Gemini Pro)")

# Khá»Ÿi táº¡o lá»‹ch sá»­
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Náº¿u pháº£i dÃ¹ng báº£n cÅ© (khÃ´ng há»— trá»£ system_instruction), ta gá»­i nÃ³ nhÆ° tin nháº¯n Ä‘áº§u tiÃªn
    if st.session_state.is_legacy_mode:
        st.session_state.messages.append({"role": "user", "content": "HÃƒY TUÃ‚N THá»¦:\n" + full_system_instruction})
        st.session_state.messages.append({"role": "model", "content": "ÄÃ£ rÃµ. TÃ´i lÃ  VÄƒn SÄ© Sá»‘."})

# Hiá»ƒn thá»‹ lá»‹ch sá»­ (áº¨n tin nháº¯n cÃ i Ä‘áº·t náº¿u á»Ÿ cháº¿ Ä‘á»™ cÅ©)
for i, message in enumerate(st.session_state.messages):
    if st.session_state.is_legacy_mode and i < 2:
        continue
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- 6. Xá»¬ LÃ NHáº¬P LIá»†U (Voice + Text) ---
st.divider()
col_mic, col_info = st.columns([1, 4])
with col_mic:
    voice_text = speech_to_text(language='vi', start_prompt="ğŸ™ï¸ NÃ³i", stop_prompt="â¹ï¸ Gá»­i", just_once=True, key='STT')

prompt = voice_text if voice_text else st.chat_input("Em cáº§n tháº§y giÃºp gÃ¬ hÃ´m nay?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    try:
        # Chuáº©n bá»‹ lá»‹ch sá»­ gá»­i Ä‘i
        history_for_model = [
            {"role": m["role"], "parts": [m["content"]]} 
            for m in st.session_state.messages 
            if m["role"] in ["user", "model"]
        ]
        
        # Gá»­i tin nháº¯n
        chat_session = model.start_chat(history=history_for_model[:-1])
        with st.chat_message("assistant"):
            with st.spinner("Äang suy nghÄ©..."):
                response = chat_session.send_message(prompt)
                st.markdown(response.text)
        
        st.session_state.messages.append({"role": "model", "content": response.text})
        
        # Äá»£i 1 chÃºt rá»“i lÃ m má»›i trang Ä‘á»ƒ xÃ³a text giá»ng nÃ³i
        time.sleep(0.5)
        st.rerun()
        
    except Exception as e:
        st.error(f"Lá»—i káº¿t ná»‘i: {e}. Tháº§y vui lÃ²ng thá»­ láº¡i sau 30 giÃ¢y.")
